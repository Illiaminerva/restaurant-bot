{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6vHqHCav9pW",
        "outputId": "9e61e2dd-b4b0-4963-f926-c46a75e0419c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "GPU is available: True\n",
            "GPU model: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install transformers tensorboard\n",
        "\n",
        "# Create project structure\n",
        "!mkdir -p src/models src/data src/training data\n",
        "\n",
        "# Check if GPU is available\n",
        "import torch\n",
        "print(\"GPU is available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU model:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import sys\n",
        "\n",
        "modules_to_reload = ['src.models.chatbot', 'src.training.train_baseline']\n",
        "for module in modules_to_reload:\n",
        "    if module in sys.modules:\n",
        "        del sys.modules[module]\n",
        "\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksIBbG9x7lgS",
        "outputId": "fb64779d-d9d2-4c86-b121-70b5cb00c627"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.models.chatbot import RestaurantChatbot\n",
        "from src.training.train_baseline import train_baseline\n",
        "\n",
        "metrics = train_baseline(\n",
        "    train_path='data/train.json',\n",
        "    val_path='data/val.json',\n",
        "    output_dir='models/baseline',\n",
        "    num_epochs=8,\n",
        "    batch_size=24,\n",
        "    warmup_steps=500,\n",
        "    max_length=128,\n",
        "    max_train_samples=8000,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")"
      ],
      "metadata": {
        "id": "lV4sK3aIzEwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12076541-597f-4add-ce73-f458cecd7320"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Training on 8000 samples for 8 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/8:   0%|          | 0/375 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "Epoch 1/8:  89%|████████▉ | 333/375 [05:27<00:41,  1.02it/s, loss=2.64]\n",
            "Validation: 100%|██████████| 42/42 [00:10<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1:\n",
            "Average training loss: 3.7451\n",
            "Average validation loss: 2.2958\n",
            "New best model saved with validation loss: 2.2958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/8:  89%|████████▉ | 333/375 [05:26<00:41,  1.02it/s, loss=2.13]\n",
            "Validation: 100%|██████████| 42/42 [00:10<00:00,  4.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2:\n",
            "Average training loss: 2.3500\n",
            "Average validation loss: 2.2168\n",
            "New best model saved with validation loss: 2.2168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/8:  89%|████████▉ | 333/375 [05:26<00:41,  1.02it/s, loss=2.31]\n",
            "Validation: 100%|██████████| 42/42 [00:10<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3:\n",
            "Average training loss: 2.2294\n",
            "Average validation loss: 2.1893\n",
            "New best model saved with validation loss: 2.1893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/8:  89%|████████▉ | 333/375 [05:25<00:41,  1.02it/s, loss=2.32]\n",
            "Validation: 100%|██████████| 42/42 [00:10<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4:\n",
            "Average training loss: 2.1496\n",
            "Average validation loss: 2.1796\n",
            "New best model saved with validation loss: 2.1796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/8:  89%|████████▉ | 333/375 [05:25<00:41,  1.02it/s, loss=2.04]\n",
            "Validation: 100%|██████████| 42/42 [00:10<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5:\n",
            "Average training loss: 2.1050\n",
            "Average validation loss: 2.1743\n",
            "New best model saved with validation loss: 2.1743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/8:  89%|████████▉ | 333/375 [05:25<00:41,  1.02it/s, loss=2.22]\n",
            "Validation: 100%|██████████| 42/42 [00:10<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6:\n",
            "Average training loss: 2.0613\n",
            "Average validation loss: 2.1747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/8:  89%|████████▉ | 333/375 [05:25<00:41,  1.02it/s, loss=2.28]\n",
            "Validation: 100%|██████████| 42/42 [00:10<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7:\n",
            "Average training loss: 2.0263\n",
            "Average validation loss: 2.1727\n",
            "New best model saved with validation loss: 2.1727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/8:  89%|████████▉ | 333/375 [05:26<00:41,  1.02it/s, loss=2.15]\n",
            "Validation: 100%|██████████| 42/42 [00:10<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8:\n",
            "Average training loss: 2.0129\n",
            "Average validation loss: 2.1735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r models.zip models/\n",
        "\n",
        "# Then download it (this will appear in Colab's file browser)\n",
        "from google.colab import files\n",
        "files.download('models.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "GEOQYdRfItoh",
        "outputId": "6a2a9d8d-4125-4ce0-e5b2-6aa5978e8287"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: models/ (stored 0%)\n",
            "  adding: models/rl/ (stored 0%)\n",
            "  adding: models/rl/logs/ (stored 0%)\n",
            "  adding: models/rl/logs/events.out.tfevents.1742529572.bf438516b6e2.696.0 (deflated 9%)\n",
            "  adding: models/rl/logs/events.out.tfevents.1742529607.bf438516b6e2.696.1 (deflated 9%)\n",
            "  adding: models/rl/logs/events.out.tfevents.1742529715.bf438516b6e2.696.2 (deflated 9%)\n",
            "  adding: models/baseline/ (stored 0%)\n",
            "  adding: models/baseline/logs/ (stored 0%)\n",
            "  adding: models/baseline/logs/events.out.tfevents.1742530209.bf438516b6e2.696.5 (deflated 9%)\n",
            "  adding: models/baseline/logs/events.out.tfevents.1742530674.bf438516b6e2.696.6 (deflated 9%)\n",
            "  adding: models/baseline/logs/events.out.tfevents.1742530004.bf438516b6e2.696.4 (deflated 9%)\n",
            "  adding: models/baseline/logs/events.out.tfevents.1742529891.bf438516b6e2.696.3 (deflated 9%)\n",
            "  adding: models/baseline/best_model.pt (deflated 7%)\n",
            "  adding: models/baseline_final/ (stored 0%)\n",
            "  adding: models/baseline_final/best_model.pt (deflated 7%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_612df85b-c7e5-40c6-a2ab-dbf2d375c432\", \"models.zip\", 923831117)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.chat_with_bot import chat_with_bot"
      ],
      "metadata": {
        "id": "ERN6NWv8kkMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_with_bot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz1eq1mfLYt1",
        "outputId": "a54abcf3-ee24-4ecf-819b-8fb99fa87ed9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restaurant Chatbot is ready! Type 'quit' to exit.\n",
            "Ask me about restaurant recommendations, cuisine types, or specific dishes.\n",
            "\n",
            "You: QUIT\n",
            "\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}